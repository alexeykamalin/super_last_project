{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7177057d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LinearRegression\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, max_error\n",
    "from sklearn.ensemble import GradientBoostingRegressor, StackingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# Улучшенный пайплайн моделирования\n",
    "def build_advanced_models():\n",
    "    # 1. Ансамбль моделей\n",
    "    base_models = [\n",
    "        ('rf', RandomForestRegressor(n_estimators=100, random_state=42)),\n",
    "        ('xgb', XGBRegressor(random_state=42)),\n",
    "        ('svr', SVR(kernel='rbf'))\n",
    "    ]\n",
    "    \n",
    "    stacking_model = StackingRegressor(\n",
    "        estimators=base_models,\n",
    "        final_estimator=LinearRegression()\n",
    "    )\n",
    "    \n",
    "    # 2. Пайплайн с предобработкой\n",
    "    models = {\n",
    "        \"Polynomial Regression\": Pipeline([\n",
    "            ('poly', PolynomialFeatures(degree=2)),\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('lr', LinearRegression())\n",
    "        ]),\n",
    "        \"Gradient Boosting\": GradientBoostingRegressor(\n",
    "            n_estimators=200, learning_rate=0.05, random_state=42\n",
    "        ),\n",
    "        \"Stacking Ensemble\": stacking_model,\n",
    "        \"XGBoost\": XGBRegressor(\n",
    "            n_estimators=300, max_depth=5, learning_rate=0.1, random_state=42\n",
    "        )\n",
    "    }\n",
    "    \n",
    "    return models\n",
    "\n",
    "def preprocess_data(df):\n",
    "    # 1. Более сложная обработка пропусков\n",
    "    for col in df.columns:\n",
    "        if df[col].isnull().sum() > 0:\n",
    "            # Для категориальных признаков используем моду\n",
    "            if df[col].nunique() < 10:\n",
    "                df[col].fillna(df[col].mode()[0], inplace=True)\n",
    "            else:\n",
    "                # Для числовых - медиану с группировкой по ball\n",
    "                df[col] = df.groupby('ball')[col].transform(lambda x: x.fillna(x.median()))\n",
    "    \n",
    "    # 2. Генерация новых признаков\n",
    "    df['total_a'] = df[['a1', 'a2', 'a3']].mean(axis=1)\n",
    "    df['total_g'] = df[['g1', 'g2', 'g3']].mean(axis=1)\n",
    "    df['total_i'] = df[['i1', 'i2', 'i3']].mean(axis=1)\n",
    "    df['total_f'] = df[['f1', 'f2', 'f3']].mean(axis=1)\n",
    "    df['total_r'] = df[['r1', 'r2', 'r3']].mean(axis=1)\n",
    "    \n",
    "    # 3. Взаимодействия признаков\n",
    "    df['a_g_interaction'] = df['ag'] * df['gg']\n",
    "    df['i_f_interaction'] = df['ig'] * df['fg']\n",
    "    \n",
    "    # 4. Биннинг непрерывных признаков\n",
    "    df['egkr_binned'] = pd.cut(df['egkr'], bins=5, labels=False)\n",
    "    \n",
    "    # 5. Логарифмирование целевой переменной (если распределение skewed)\n",
    "    if np.abs(df['ball'].skew()) > 1:\n",
    "        df['ball_log'] = np.log1p(df['ball'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "def postprocess_predictions(y_pred, y_train):\n",
    "    # 1. Округление до ближайшего реального значения из train\n",
    "    unique_values = np.sort(y_train.unique())\n",
    "    y_pred_rounded = np.array([unique_values[np.argmin(np.abs(unique_values - val))] for val in y_pred])\n",
    "    \n",
    "    # 2. Калибровка предсказаний\n",
    "    q_train = np.percentile(y_train, np.linspace(0, 100, 101))\n",
    "    q_pred = np.percentile(y_pred, np.linspace(0, 100, 101))\n",
    "    y_pred_calibrated = np.interp(y_pred, q_pred, q_train)\n",
    "    \n",
    "    # 3. Ограничение диапазона\n",
    "    y_pred_final = np.clip(y_pred_calibrated, y_train.min(), y_train.max())\n",
    "    \n",
    "    return y_pred_final\n",
    "\n",
    "def advanced_model_analysis(models, X_train, X_test, y_train, y_test):\n",
    "    results = []\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        # Обучение модели\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Предсказания\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Постобработка\n",
    "        y_pred_processed = postprocess_predictions(y_pred, y_train)\n",
    "        \n",
    "        # Метрики\n",
    "        metrics = {\n",
    "            'Model': name,\n",
    "            'R2': r2_score(y_test, y_pred_processed),\n",
    "            'MAE': mean_absolute_error(y_test, y_pred_processed),\n",
    "            'RMSE': np.sqrt(mean_squared_error(y_test, y_pred_processed)),\n",
    "            'Max Error': max_error(y_test, y_pred_processed)\n",
    "        }\n",
    "        results.append(metrics)\n",
    "        \n",
    "        # Визуализация\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.scatterplot(x=y_test, y=y_pred_processed)\n",
    "        plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--')\n",
    "        plt.title(f'{name} - Actual vs Predicted')\n",
    "        plt.xlabel('Actual')\n",
    "        plt.ylabel('Predicted')\n",
    "        plt.show()\n",
    "        \n",
    "        # Ошибки по диапазонам\n",
    "        error_df = pd.DataFrame({'Actual': y_test, 'Error': y_test - y_pred_processed})\n",
    "        error_df['Range'] = pd.cut(error_df['Actual'], bins=5)\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.boxplot(x='Range', y='Error', data=error_df)\n",
    "        plt.title(f'{name} - Error Distribution by Actual Value Range')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.show()\n",
    "    \n",
    "    # Сравнительная таблица метрик\n",
    "    results_df = pd.DataFrame(results)\n",
    "    print(\"\\nСравнение моделей:\")\n",
    "    print(results_df.sort_values('R2', ascending=False))\n",
    "    \n",
    "    # Feature importance для tree-based моделей\n",
    "    for name, model in models.items():\n",
    "        if hasattr(model, 'feature_importances_'):\n",
    "            plt.figure(figsize=(12, 8))\n",
    "            feat_importances = pd.Series(model.feature_importances_, index=X_train.columns)\n",
    "            feat_importances.nlargest(15).plot(kind='barh')\n",
    "            plt.title(f'{name} - Feature Importance')\n",
    "            plt.show()\n",
    "        elif hasattr(model, 'coef_'):\n",
    "            plt.figure(figsize=(12, 8))\n",
    "            coef = pd.Series(model.coef_, index=X_train.columns)\n",
    "            coef.abs().nlargest(15).plot(kind='barh')\n",
    "            plt.title(f'{name} - Feature Coefficients (absolute values)')\n",
    "            plt.show()\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "# Основной пайплайн\n",
    "df = pd.read_csv(\"super_new_dataset.csv\", sep=';')\n",
    "\n",
    "# Улучшенная предобработка\n",
    "df = preprocess_data(df)\n",
    "\n",
    "# Разделение данных\n",
    "X = df.drop(columns=[\"hash\", \"ball\"])\n",
    "y = df[\"ball\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Построение и оценка моделей\n",
    "models = build_advanced_models()\n",
    "results = advanced_model_analysis(models, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Анализ остатков лучшей модели\n",
    "best_model_name = results.iloc[results['R2'].idxmax()]['Model']\n",
    "best_model = models[best_model_name]\n",
    "y_pred = postprocess_predictions(best_model.predict(X_test), y_train)\n",
    "residuals = y_test - y_pred\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(residuals, kde=True)\n",
    "plt.title(f'{best_model_name} - Distribution of Residuals')\n",
    "plt.xlabel('Residuals')\n",
    "plt.show()\n",
    "\n",
    "# Q-Q plot для проверки нормальности остатков\n",
    "from scipy import stats\n",
    "plt.figure(figsize=(10, 6))\n",
    "stats.probplot(residuals, dist=\"norm\", plot=plt)\n",
    "plt.title(f'{best_model_name} - Q-Q Plot')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
